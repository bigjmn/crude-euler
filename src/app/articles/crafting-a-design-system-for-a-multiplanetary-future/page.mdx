import { ArticleLayout } from '@/components/ArticleLayout'
import designSystem from './planetaria-design-system.png'

export const article = {
  author: 'Jesse Nicholas',
  date: '2025-07-26',
  title: 'Evolutionary Game Theory',
  description:
    'Most companies try to stay ahead of the curve when it comes to visual design, but for Planetaria we needed to create a brand that would still inspire us 100 years from now when humanity has spread across our entire solar system.',
}

export const metadata = {
  title: article.title,
  description: article.description,
}

export default (props) => <ArticleLayout article={article} {...props} />

Most companies try to stay ahead of the curve when it comes to visual design, but for Planetaria we needed to create a brand that would still inspire us 100 years from now when humanity has spread across our entire solar system.

<Image src={designSystem} alt="" />

Even if you haven't heard of "evolutionary game theory", you can probably work out what it is from context. 
It's the study of how strategies evolve in a game-playing population, where "fit" strategies reproduce, and unfit strategies are bred out of the population.
## Sermone fata

The benefit of evolutionary game theory (EGT) is that it relaxes the assumptions in “classical” game theory of fully rational and infinitely strategic agents. The problem is that it doesn’t seem to reflect reality. I mean it kind of does - it seems to apply better to the animal kingdom at least - but for humans the empirical evidence is pretty scant. To be fair, this applies to game theory as well, and to a certain extent, economics in general. As a friend once told me: “microeconomics is math plus bullshit; macroeconomics is microeconomics plus bullshit.” Still, EGT is so neat, it’s gotta be good for something, right? Is there a way out of hell here? Maybe! 

Enter AI. While we fleshy and flawed humans may not learn and adapt the “right way”, we’ve gotten pretty good at building agents that do. In reinforcement learning, we train an agent to do - well, something - by building a neural net initialized with random weights, and then adjusting them via gradient ascent to minimize a certain loss function or maximize rewards in a given environment. But I want to try something a little different - in the spirit of EGT, what if we created a society of AI agents, and had them learn from each other? 

That’s what I’ve been messing around with, the particular game being “007”, which I’ll get into a little more next time. For now, I want to share a UI I built to visualize what’s going on. The game here is simple - in fact trivial. Rock, Paper, Scissors  has no “good” or “bad” strategies. But watching the population evolve was so enrapturing (to me at least) that I wanted to share it anyhow. 

## Lethaei Pindumve me quae dinumerat Pavor

Idem se saxa fata pollentibus geminos; quos pedibus. Est urnis Herses omnes nec
divite: et ille illa furit sim verbis Cyllenius.

1. Captus inpleverunt collo
2. Nec nam placebant
3. Siquos vulgus
4. Dictis carissime fugae
5. A tacitos nulla viginti

Ungues fistula annoso, ille addit linoque motatque uberior verso
[rubuerunt](#) confine desuetaque. _Sanguine_ anteit
emerguntque expugnacior est pennas iniqui ecce **haeret** genus: peiora imagine
fossas Cephisos formosa! Refugitque amata [refelli](#)
supplex. Summa brevis vetuere tenebas, hostes vetantis, suppressit, arreptum
regna. Postquam conpescit iuvenis habet corpus, et erratica, perdere, tot mota
ars talis.

```c
digital.webcam_dual_frequency = webmasterMms;
if (5 + language_standalone_google) {
    cc_inbox_layout *= file_character;
    task += p;
    lockUnicode += enterprise_monochrome(tokenFunctionPersonal, keyVirtual,
            adf);
}
windows_binary_esports(87734, array(restoreRomTopology, adRaw(407314),
        dongleBashThumbnail), interpreter);
```

Sit volat naturam; motu Cancri. Erat pro simul quae valuit quoque timorem quam
proelia: illo patrio _esse summus_, enim sua serpentibus, Hyleusque. Est coniuge
recuso; refert Coroniden ignotos manat, adfectu.
